{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.jit import script, trace\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy import signal\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eeg_s = [\n",
    "#    np.load(\"preprocessed_data_Sandra.npy\"),\n",
    "#    np.load(\"preprocessed_data_Ethan.npy\"),\n",
    "#]\n",
    "\n",
    "eeg_s = [\n",
    "    np.load(\"eeg-data/preprocessed_data_Sandra.npy\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1676, 8, 750)\n"
     ]
    }
   ],
   "source": [
    "def condense_preprocessed_data(eeg_pre):\n",
    "    return np.array(\n",
    "        [\n",
    "            eeg_pre[i, :, j, :]\n",
    "            for i in range(23)\n",
    "            for j in range(eeg_pre.shape[2])\n",
    "            if np.sum(eeg_pre[i, :, j, :]) != 0\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Combine all sessions into one array\n",
    "eeg_data = np.vstack([condense_preprocessed_data(session) for session in eeg_s])\n",
    "\n",
    "print(eeg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_notch_filter(data, fs=250, f0=60, Q=30):\n",
    "    nyq = 0.5 * fs\n",
    "    w0 = f0 / nyq\n",
    "    b, a = signal.iirnotch(w0, Q)\n",
    "    filtered_data = signal.filtfilt(b, a, data, axis=-1)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "# Apply the notch filter to the EEG data\n",
    "eeg_data = apply_notch_filter(eeg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VAD/Emotion Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emocsv = pd.read_csv(\"emotion-data/emotion_data.csv\")\n",
    "emocsv1 = emocsv.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"How feel\", \"Pos\", \"Energ\", \"Dom\", \"Content\", \"Amused\", \"Angry\", \"Sad\", \"Disgust\", \"Afraid\", \"Emo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            How feel Pos Energ Dom Content  \\\n",
      "0  disgusted, but the music made the video funny,...   2     3   7       1   \n",
      "0                                          disgusted   2     3   7       1   \n",
      "0                                          disgusted   1     5   7       1   \n",
      "0                                            relaxed   6     5   8       3   \n",
      "0                                         moved, sad   3     4   3       1   \n",
      "0                                                sad   2     5   4       1   \n",
      "0                                         angry, sad   1     6   3       1   \n",
      "0                                            neutral   5     3   5       1   \n",
      "0                                              angry   2     5   4       1   \n",
      "0                                            annoyed   1     5   2       1   \n",
      "0              a little bit annoyed, overall neutral   3     5   6       1   \n",
      "0                                            neutral   5     5   7       1   \n",
      "0                                            neutral   6     5   6       2   \n",
      "0                                            relaxed   7     5   7       3   \n",
      "0                            a little bit of content   6     5   6       3   \n",
      "0                                            neutral   5     5   5       1   \n",
      "0                                             scared   3     4   1       1   \n",
      "0                                             scared   2     6   1       1   \n",
      "0                                             scared   2     7   1       1   \n",
      "0                                            neutral   5     5   7       1   \n",
      "0                    content and a little bit amused   7     6   6       3   \n",
      "0                            content, a little amuse   7     5   7       3   \n",
      "0                                              funny   7     6   7       3   \n",
      "1  the sound shocked me but it was cute so it mad...   7     9   5       4   \n",
      "1  i laughed because it went on for so long but i...   7     8   8       5   \n",
      "1  I LOVED IT SO MUCH I AM SO HAPPY WATCHING THE ...   9     9   9       5   \n",
      "1  that was so annoying i honestly am just reliev...   3     2   6       1   \n",
      "1  disappointed that there wasn't a jump scare so...   5     9   3       3   \n",
      "1  kinda disappointed in how not-scary the jump s...   2     2   5       1   \n",
      "1              amused but that was a terrible video    9     9   9       3   \n",
      "1                        content but pretty neutral    7     4   7       4   \n",
      "1  angry and sad about our law enforcement/justic...   1     7   8       1   \n",
      "1  kinda annoying that i couldn't hear most of it...   4     1   2       1   \n",
      "1                     annoyed, frustrated, confused    1     3   6       1   \n",
      "1                               sad, tired, neutral    2     2   4       1   \n",
      "1          so cute but went on for too long -- happy   9     7   8       5   \n",
      "1                  so cute, great length -- content    9     3   9       5   \n",
      "1  it was really funny, kinda annoying that parts...   9     8   7       5   \n",
      "1                                     really annoyed   2     5   7       1   \n",
      "1                                   sad, bittersweet   3     7   2       2   \n",
      "1   frustrated that something like this would happen   2     3   3       1   \n",
      "1                               interested, content    6     2   6       3   \n",
      "1                                woefully disgusted    1     7   1       1   \n",
      "1                                      so disgusted    1     8   2       1   \n",
      "1                                         satisfied    5     4   4       3   \n",
      "1                                        devastated    2     9   1       1   \n",
      "\n",
      "  Amused Angry Sad Disgust Afraid                    Emo  \n",
      "0      2     4   1       5      1              Disgusted  \n",
      "0      1     1   1       5      1              Disgusted  \n",
      "0      1     1   1       5      1              Disgusted  \n",
      "0      1     1   1       1      1  Neutral (unemotional)  \n",
      "0      1     1   3       1      1                    Sad  \n",
      "0      1     2   4       1      1                    Sad  \n",
      "0      1     5   4       4      3                  Angry  \n",
      "0      1     1   1       1      1  Neutral (unemotional)  \n",
      "0      1     4   1       1      1                  Angry  \n",
      "0      1     4   3       3      1                  Angry  \n",
      "0      1     2   1       1      1  Neutral (unemotional)  \n",
      "0      1     1   1       1      1  Neutral (unemotional)  \n",
      "0      1     1   1       1      1  Neutral (unemotional)  \n",
      "0      1     1   1       1      1                Content  \n",
      "0      1     1   1       1      1                Content  \n",
      "0      1     1   1       1      1  Neutral (unemotional)  \n",
      "0      1     1   1       1      5                 Afraid  \n",
      "0      1     1   1       1      5                 Afraid  \n",
      "0      1     1   1       1      5                 Afraid  \n",
      "0      1     1   1       1      1  Neutral (unemotional)  \n",
      "0      1     1   1       1      1                Content  \n",
      "0      2     1   1       1      1                Content  \n",
      "0      5     1   1       1      1                 Amused  \n",
      "1      5     1   1       1      3                 Amused  \n",
      "1      5     2   1       1      1                 Amused  \n",
      "1      5     1   1       1      1                 Amused  \n",
      "1      1     3   1       2      1                  Angry  \n",
      "1      3     4   1       2      2                  Angry  \n",
      "1      1     4   1       1      1                  Angry  \n",
      "1      4     1   1       1      1                 Amused  \n",
      "1      2     1   1       1      1  Neutral (unemotional)  \n",
      "1      1     5   4       5      2                  Angry  \n",
      "1      1     2   1       1      1  Neutral (unemotional)  \n",
      "1      1     4   1       1      1                  Angry  \n",
      "1      1     1   3       1      3                 Afraid  \n",
      "1      5     1   1       1      1                 Amused  \n",
      "1      5     1   1       1      1                Content  \n",
      "1      5     1   1       1      1                 Amused  \n",
      "1      1     3   1       2      1  Neutral (unemotional)  \n",
      "1      1     1   4       1      1                    Sad  \n",
      "1      1     3   2       2      1                  Angry  \n",
      "1      1     1   1       1      1                Content  \n",
      "1      1     1   1       5      1                    NaN  \n",
      "1      1     2   1       5      1              Disgusted  \n",
      "1      2     1   1       4      1                 Amused  \n",
      "1      1     1   5       1      1                    Sad  \n"
     ]
    }
   ],
   "source": [
    "emo_labels = pd.DataFrame()\n",
    "\n",
    "for row in range(2):\n",
    "    sel_row = emocsv1.iloc[row]\n",
    "    for i in np.arange(0, emocsv1.shape[1], 11):\n",
    "        obs = sel_row[i : i + 11].to_frame().T\n",
    "        obs = obs.rename(columns={obs.columns[i]: new_cols[i] for i in range(11)})\n",
    "        emo_labels = pd.concat([emo_labels, obs])\n",
    "print(emo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_labels[\"Pos2\"] = emo_labels[\"Pos\"]\n",
    "emo_labels[\"Energ2\"] = emo_labels[\"Energ\"]\n",
    "emo_labels[\"Dom2\"] = emo_labels[\"Dom\"]\n",
    "\n",
    "#emo_labels[\"Pos2\"] = (emo_labels[\"Pos\"] > 4) + 0\n",
    "#emo_labels[\"Energ2\"] = (emo_labels[\"Energ\"] > 4) + 0\n",
    "#emo_labels[\"Dom2\"] = (emo_labels[\"Dom\"] > 4) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence = emo_labels['Pos2'].to_numpy()\n",
    "arousal = emo_labels['Energ2'].to_numpy()\n",
    "dominance = emo_labels['Dom2'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n"
     ]
    }
   ],
   "source": [
    "y1, y2, y3 = [], [], []  # VAD labels given for each 3-second data chunk\n",
    "\n",
    "for session_number, session in enumerate(eeg_s):\n",
    "    for i in range(23):\n",
    "        j = 0\n",
    "        while j < session.shape[2] and np.sum(session[i, :, j, :]) != 0:\n",
    "            idx = i + session_number * 23\n",
    "            y1.append(valence[idx])\n",
    "            y2.append(arousal[idx])\n",
    "            y3.append(dominance[idx])\n",
    "            j += 1\n",
    "\n",
    "print(\n",
    "    len(y1)\n",
    ")  # this corresponds to the number of 3-second chunks across all data chunks. 1676 -> ~ 4 minutes per video on average, checks out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "y3 = np.array(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 979, 1336,  881, ..., 1096,  235, 1061])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(len(eeg_data))\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(indices)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1676, Train: 670, Validation: 670, Test: 336\n"
     ]
    }
   ],
   "source": [
    "# Define the split ratios\n",
    "ratios = [0.4, 0.4, 0.2]\n",
    "train_ratio, valid_ratio, test_ratio = ratios\n",
    "\n",
    "# Calculate split points\n",
    "train_end = int(len(indices) * train_ratio)\n",
    "valid_end = int(len(indices) * (train_ratio + valid_ratio))\n",
    "test_end = int(len(indices) * (train_ratio + valid_ratio + test_ratio))\n",
    "\n",
    "# Split the indices\n",
    "train_indices, valid_indices, test_indices = (\n",
    "    indices[:train_end],\n",
    "    indices[train_end:valid_end],\n",
    "    indices[valid_end:test_end],\n",
    ")\n",
    "\n",
    "# Print lengths of each split\n",
    "print(\n",
    "    f\"Total: {len(indices)}, Train: {len(train_indices)}, Validation: {len(valid_indices)}, Test: {len(test_indices)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = eeg_data[train_indices]\n",
    "y_train_v = y1[train_indices]\n",
    "y_train_a = y2[train_indices]\n",
    "y_train_d = y3[train_indices]\n",
    "\n",
    "x_valid = eeg_data[valid_indices]\n",
    "y_valid_v = y1[valid_indices]\n",
    "y_valid_a = y2[valid_indices]\n",
    "y_valid_d = y3[valid_indices]\n",
    "\n",
    "x_test = eeg_data[test_indices]\n",
    "y_test_v = y1[test_indices]\n",
    "y_test_a = y2[test_indices]\n",
    "y_test_d = y3[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "train_subset_v = torch.utils.data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train_v))\n",
    "val_subset_v = torch.utils.data.TensorDataset(torch.Tensor(x_valid), torch.Tensor(y_valid_v))\n",
    "test_dataset_v = torch.utils.data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test_v))\n",
    "\n",
    "train_subset_a = torch.utils.data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train_a))\n",
    "val_subset_a = torch.utils.data.TensorDataset(torch.Tensor(x_valid), torch.Tensor(y_valid_a))\n",
    "test_dataset_a = torch.utils.data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test_a))\n",
    "\n",
    "train_subset_d = torch.utils.data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train_d))\n",
    "val_subset_d = torch.utils.data.TensorDataset(torch.Tensor(x_valid), torch.Tensor(y_valid_d))\n",
    "test_dataset_d = torch.utils.data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test_d))\n",
    "\n",
    "bsz = 50\n",
    "\n",
    "train_loader_v = torch.utils.data.DataLoader(train_subset_v, shuffle=True, batch_size=bsz)\n",
    "val_loader_v = torch.utils.data.DataLoader(val_subset_v, shuffle=False, batch_size=bsz)\n",
    "test_loader_v = torch.utils.data.DataLoader(test_dataset_v, shuffle=False, batch_size=bsz)\n",
    "\n",
    "train_loader_a = torch.utils.data.DataLoader(train_subset_a, shuffle=True, batch_size=bsz)\n",
    "val_loader_a = torch.utils.data.DataLoader(val_subset_a, shuffle=False, batch_size=bsz)\n",
    "test_loader_a = torch.utils.data.DataLoader(test_dataset_a, shuffle=False, batch_size=bsz)\n",
    "\n",
    "train_loader_d = torch.utils.data.DataLoader(train_subset_d, shuffle=True, batch_size=bsz)\n",
    "val_loader_d = torch.utils.data.DataLoader(val_subset_d, shuffle=False, batch_size=bsz)\n",
    "test_loader_d = torch.utils.data.DataLoader(test_dataset_d, shuffle=False, batch_size=bsz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_time = 750\n",
    "n_channels = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=8, out_channels=40, kernel_size=20, stride=4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(40)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        self.lstm1 = nn.LSTM(input_size=45, hidden_size=30)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(40)\n",
    "        self.lstm2 = nn.LSTM(input_size=30, hidden_size=10)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(40)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense = nn.Linear(400,2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 750])\n",
      "tensor([[0.5573, 0.4427]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_size = (n_channels, samp_time)\n",
    "\n",
    "# Random input tensor with the specified dimensions\n",
    "input_tensor = torch.randn(1, *input_size)\n",
    "print(input_tensor.shape)\n",
    "\n",
    "# create neural networks\n",
    "v_net = CNN_LSTM()\n",
    "print(v_net.forward(Variable(input_tensor)))\n",
    "v_criterion = nn.CrossEntropyLoss() # add to device here\n",
    "v_optimizer = optim.Adam(v_net.parameters(), lr=0.001, weight_decay=1e-7)\n",
    "\n",
    "a_net = CNN_LSTM()\n",
    "a_criterion = nn.CrossEntropyLoss() # add to device here\n",
    "a_optimizer = optim.Adam(a_net.parameters(), lr=0.001, weight_decay=1e-7)\n",
    "\n",
    "d_net = CNN_LSTM()\n",
    "d_criterion = nn.CrossEntropyLoss() # add to device here\n",
    "d_optimizer = optim.Adam(d_net.parameters(), lr=0.001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM_Reg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM_Reg, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=8, out_channels=40, kernel_size=20, stride=4\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(40)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        self.lstm1 = nn.LSTM(input_size=45, hidden_size=30)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(40)\n",
    "        self.lstm2 = nn.LSTM(input_size=30, hidden_size=10)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(40)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense = nn.Linear(400, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 750])\n",
      "tensor([[-0.1854]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_size = (n_channels, samp_time)\n",
    "\n",
    "# Random input tensor with the specified dimensions\n",
    "input_tensor = torch.randn(1, *input_size)\n",
    "print(input_tensor.shape)\n",
    "\n",
    "# create neural networks\n",
    "clr_net = CNN_LSTM_Reg()\n",
    "print(clr_net.forward(Variable(input_tensor)))\n",
    "clr_criterion = nn.MSELoss()  # add to device here\n",
    "clr_optimizer = optim.Adam(d_net.parameters(), lr=0.001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, optimizer, criterion, train_loader, val_loader, num_epochs):\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "\n",
    "    for epoch_idx in tqdm(range(num_epochs)):\n",
    "        net.train()\n",
    "        #train_count = 0\n",
    "        #train_correct_count = 0\n",
    "        for batch_idx, (train_x, train_y) in enumerate(train_loader):\n",
    "            train_x = train_x.float()\n",
    "            train_y = train_y.float()\n",
    "            optimizer.zero_grad()\n",
    "            op = net(train_x)\n",
    "            loss = criterion(op, train_y)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #with torch.no_grad():\n",
    "            #    y_hat = logits.item()\n",
    "            #    train_correct_count += torch.sum(y_hat == train_y, axis=-1)\n",
    "            #    train_count += train_x.size(0)\n",
    "\n",
    "        #train_acc = train_correct_count / train_count\n",
    "        #train_hist.append(train_acc)\n",
    "\n",
    "        net.eval()\n",
    "        #val_count = 0\n",
    "        #val_correct_count = 0\n",
    "        #with torch.no_grad():\n",
    "        #    for idx, (val_x, val_y) in enumerate(val_loader):\n",
    "        #        val_x = val_x.float()\n",
    "        #        val_y = val_y.float()\n",
    "        #        logits = net(val_x).detach()\n",
    "        #        y_hat = torch.argmax(logits, dim=-1)\n",
    "                #val_correct_count += torch.sum(y_hat == val_y, axis=-1)\n",
    "                #val_count += val_x.size(0)\n",
    "        #val_acc = val_correct_count / val_count\n",
    "        #val_hist.append(val_acc)\n",
    "        #print('Train acc: {:.3f}, Val acc: {:.3f}'.format(train_acc, val_acc))\n",
    "\n",
    "    #plt.plot(train_hist)\n",
    "    #plt.plot(val_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, test_loader):\n",
    "    net.eval()\n",
    "    test_count = 0\n",
    "    test_correct_count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (test_x, test_y) in enumerate(test_loader):\n",
    "            test_x = test_x.float()\n",
    "            test_y = test_y.long()\n",
    "            logits = net(test_x).detach()\n",
    "            y_hat = torch.argmax(logits, dim=-1)\n",
    "            test_correct_count += torch.sum(y_hat == test_y, axis=-1)\n",
    "            test_count += test_x.size(0)\n",
    "    test_acc = test_correct_count / test_count\n",
    "\n",
    "    print('Test acc: {:.10f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.8624, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0628, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7708, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.1854, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8513, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  2%|▏         | 1/50 [00:00<00:23,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.7106, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.2397, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7006, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1191, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6864, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.6115, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6894, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1014, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6800, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.3126, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7259, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7439, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2529, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3030, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6705, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4227, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7211, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:00<00:18,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.9474, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5549, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0047, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0729, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6682, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7729, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5497, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7035, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2373, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4065, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4980, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7632, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7850, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7909, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4673, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0408, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2369, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:01<00:17,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.6731, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5380, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8135, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7250, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.4696, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0309, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9200, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1303, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:01<00:16,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.0883, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2001, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5490, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4489, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0442, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7359, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1613, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4606, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9494, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4474, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.5252, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3221, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3450, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7540, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3102, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6131, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3651, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:01<00:16,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.0985, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3970, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2620, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.4453, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.4182, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7348, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2516, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1036, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7454, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:02<00:15,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27.0176, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8317, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1089, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0252, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0235, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8692, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2822, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4307, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3273, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8854, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8876, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3006, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0183, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.2275, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4032, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5461, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8412, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:02<00:15,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.5826, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.3782, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6616, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5413, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1363, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1421, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3965, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.0682, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4202, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7715, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4098, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6059, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4254, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0845, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3806, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7623, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5567, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5710, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:02<00:14,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.1347, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2878, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7262, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7192, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4660, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0515, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7464, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7109, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7206, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:03<00:14,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.8361, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6760, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.3301, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8015, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7105, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.9507, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5510, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6097, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5657, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3379, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9776, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0470, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7843, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6956, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9903, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0061, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:03<00:14,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29.4680, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2742, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.7895, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2883, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8902, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7889, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8301, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.3347, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4556, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0942, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.5949, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3333, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8621, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8377, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3458, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1525, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0794, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:03<00:13,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.2565, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9310, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0548, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.5233, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9515, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5686, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0012, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:04<00:13,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.8656, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3626, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4898, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5195, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4790, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3878, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5843, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0852, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4545, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8296, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4145, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3149, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9231, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4560, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9456, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1991, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0070, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:04<00:13,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.4349, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3402, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0903, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1721, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0786, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7349, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6268, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.5910, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9779, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2940, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9202, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6172, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0585, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2042, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8501, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0479, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4822, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:05<00:13,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.8405, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0543, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6156, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0618, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8651, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1116, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.5560, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6136, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.0536, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:05<00:12,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.6831, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2173, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3456, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5199, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6049, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3487, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7095, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.0874, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2317, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4625, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.8669, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2919, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9773, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7392, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6646, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7732, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3689, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6618, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:05<00:12,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.3845, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0302, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7766, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2404, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7800, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0179, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3172, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7508, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1693, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6506, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2072, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4347, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0361, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3156, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.5751, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:06<00:12,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.5936, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.9686, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3870, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4695, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6980, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6056, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5423, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6450, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5198, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:06<00:11,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.4469, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8060, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7964, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9340, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8918, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6305, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7934, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4163, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1611, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7525, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0182, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7322, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9708, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3416, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0751, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7878, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9658, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1113, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:06<00:10,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.4363, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6393, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1643, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2879, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6914, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9420, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9572, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2816, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1522, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4342, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9096, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9489, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8088, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9490, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:07<00:11,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.1655, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4452, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5035, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6995, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1352, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.1752, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.7950, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0954, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9342, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:07<00:10,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.2826, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8196, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3068, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2689, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1349, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3786, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2277, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5388, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6441, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1796, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8319, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6582, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8621, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8278, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3248, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6876, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:07<00:09,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.9959, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8915, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9718, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2409, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3683, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6662, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0912, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8988, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6591, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:08<00:09,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.0287, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0164, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5260, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2652, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1924, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4517, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9693, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4842, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.9584, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6194, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6594, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4112, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4100, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0344, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.5718, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.7696, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:08<00:09,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.0193, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7980, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7042, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1754, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5064, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8501, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6049, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3068, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1683, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0846, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9657, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8754, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8390, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1322, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9641, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9222, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.4631, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3974, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9866, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:08<00:08,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.2391, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3612, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0974, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3707, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8428, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3559, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3621, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5023, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8265, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:09<00:08,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.3076, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7662, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4718, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3687, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2364, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.3177, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2200, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2319, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4307, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8728, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4492, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9767, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6609, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.2835, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8677, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2984, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4420, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1482, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:09<00:07,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.2572, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3674, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5167, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6107, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0973, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7201, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8759, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0842, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6711, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:10<00:07,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.4641, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6112, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1482, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2442, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8324, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4866, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8574, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6608, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.6424, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0111, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4987, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1255, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9566, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4626, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7746, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8601, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:10<00:07,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.3674, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3018, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9577, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0356, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6807, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5121, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8976, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0067, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6917, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:10<00:06,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.2912, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6306, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2345, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0558, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9055, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.6418, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4582, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4635, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9293, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4986, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9633, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2530, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.9712, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7332, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6380, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2798, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7074, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.6441, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:11<00:06,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.2711, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5854, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5604, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1849, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.4671, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.0099, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8106, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4096, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5762, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.3481, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.0608, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8576, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2353, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7924, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.0690, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5164, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9193, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:11<00:06,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33.0131, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5664, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1979, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3486, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3436, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6391, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1239, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8648, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3425, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:11<00:05,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29.7574, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4847, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5451, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9321, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8633, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9444, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0138, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0583, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8150, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.5110, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5424, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1823, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2447, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6014, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8559, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6102, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [00:12<00:05,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.1797, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.3961, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0715, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6087, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7468, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5228, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7808, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.1492, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1551, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:12<00:05,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.6153, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0583, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9692, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5992, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5758, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9711, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.3183, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.8649, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3608, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0795, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6398, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9291, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4754, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7400, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3118, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9414, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:12<00:04,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.8287, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.2462, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7349, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3143, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3624, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8678, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1876, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4719, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4163, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8981, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5324, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8060, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0678, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1303, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2550, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5137, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9585, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0730, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:13<00:04,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.5059, grad_fn=<MseLossBackward0>)\n",
      "tensor(18.4040, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2128, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5520, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3998, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5898, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.8862, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6665, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8894, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4209, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:13<00:04,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27.4979, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8093, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2021, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2069, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7607, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.3752, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6004, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8062, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1762, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9354, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5182, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2569, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6236, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8752, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5634, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3452, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1775, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8425, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [00:13<00:03,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.1103, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9464, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3391, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4281, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3803, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5374, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.3019, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2748, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2524, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9372, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5687, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0361, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6949, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1669, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0956, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5918, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:14<00:03,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.8421, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1624, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6196, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2038, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3467, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5141, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9960, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9584, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:14<00:03,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.4707, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5351, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7328, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8714, grad_fn=<MseLossBackward0>)\n",
      "tensor(16.3465, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9232, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9018, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7242, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4967, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9483, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4023, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.4655, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5091, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5209, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8907, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0822, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [00:14<00:02,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7488, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.2672, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1882, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.3473, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5056, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6100, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.8285, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8294, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:15<00:02,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.1850, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7797, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0296, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6195, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0533, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7880, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5516, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2431, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1722, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6091, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2513, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1299, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0359, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7682, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4366, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:15<00:02,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.1809, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1041, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0294, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4370, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5705, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4178, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5554, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6620, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0541, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8806, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6038, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1140, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2683, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6028, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.4913, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4794, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1116, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:16<00:01,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.2359, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5388, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5838, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.3308, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5662, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8190, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0163, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.6241, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [00:16<00:01,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.8316, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3997, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0154, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2786, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3280, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7037, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8513, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6647, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6396, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.1350, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7595, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1743, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7788, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4739, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.6290, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2451, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3449, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4007, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:16<00:01,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.5948, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5364, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.7748, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5468, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2960, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1090, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7648, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0375, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7330, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8151, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1960, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6892, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9140, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7836, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0710, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:17<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.6237, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1738, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0792, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.3537, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3558, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0405, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9972, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8408, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9788, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:17<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.2156, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6919, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5810, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8067, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9068, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0259, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8447, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.5957, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8110, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2687, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8958, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2230, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6512, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2285, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4573, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7098, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8282, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.5004, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1539, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7640, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4186, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_net(clr_net, clr_optimizer, clr_criterion, train_loader_v, val_loader_v, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mtrain_net\u001b[0;34m(net, optimizer, criterion, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m op \u001b[38;5;241m=\u001b[39m net(train_x)\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "train_net(v_net, v_optimizer, v_criterion, train_loader_v, val_loader_v, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.1696428508\n"
     ]
    }
   ],
   "source": [
    "eval_net(v_net, test_loader_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mtrain_net\u001b[0;34m(net, optimizer, criterion, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m op \u001b[38;5;241m=\u001b[39m net(train_x)\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "train_net(a_net, a_optimizer, a_criterion, train_loader_a, val_loader_a, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8060959578\n"
     ]
    }
   ],
   "source": [
    "eval_net(a_net, test_loader_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:00<00:04, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.672, Val acc: 0.716\n",
      "Train acc: 0.522, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:00<00:02, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.731, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.701, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:00<00:01, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:00<00:01, 24.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:01<00:00, 25.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:01<00:00, 25.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.701, Val acc: 0.716\n",
      "Train acc: 0.731, Val acc: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:01<00:00, 25.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.716, Val acc: 0.716\n",
      "Train acc: 0.701, Val acc: 0.731\n",
      "Train acc: 0.731, Val acc: 0.716\n",
      "Train acc: 0.701, Val acc: 0.716\n",
      "Train acc: 0.731, Val acc: 0.716\n",
      "Train acc: 0.761, Val acc: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:01<00:00, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.731, Val acc: 0.716\n",
      "Train acc: 0.716, Val acc: 0.701\n",
      "Train acc: 0.701, Val acc: 0.701\n",
      "Train acc: 0.731, Val acc: 0.701\n",
      "Train acc: 0.761, Val acc: 0.701\n",
      "Train acc: 0.746, Val acc: 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:02<00:00, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.731, Val acc: 0.761\n",
      "Train acc: 0.746, Val acc: 0.761\n",
      "Train acc: 0.806, Val acc: 0.776\n",
      "Train acc: 0.791, Val acc: 0.776\n",
      "Train acc: 0.836, Val acc: 0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 24.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.761, Val acc: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_net(d_net, d_optimizer, d_criterion, train_loader_d, val_loader_d, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.7522698045\n"
     ]
    }
   ],
   "source": [
    "eval_net(d_net, test_loader_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(v_net.state_dict(), cwd + '/vnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(a_net.state_dict(), cwd + '/anet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d_net.state_dict(), cwd + 'dnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = CNN_LSTM()\n",
    "tester.load_state_dict(torch.load(cwd + '/vnet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotions (for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM2, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=8, out_channels=40, kernel_size=20, stride=4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(40)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        self.lstm1 = nn.LSTM(input_size=45, hidden_size=30)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(40)\n",
    "        self.lstm2 = nn.LSTM(input_size=30, hidden_size=10)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(40)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense = nn.Linear(400,6)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 750])\n",
      "tensor([[0.1739, 0.1834, 0.1254, 0.3558, 0.1200, 0.0415]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_size = (n_channels, samp_time)\n",
    "\n",
    "# Random input tensor with the specified dimensions\n",
    "input_tensor = torch.randn(1, *input_size)\n",
    "print(input_tensor.shape)\n",
    "\n",
    "# create neural networks\n",
    "emo_net = CNN_LSTM2()\n",
    "print(emo_net.forward(Variable(input_tensor)))\n",
    "e_criterion = nn.CrossEntropyLoss() # add to device here\n",
    "e_optimizer = optim.Adam(emo_net.parameters(), lr=0.001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_emotions = emo_labels['Emo']\n",
    "formal_emotions = formal_emotions.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_emotions = formal_emotions.reshape((formal_emotions.size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat = OneHotEncoder()\n",
    "emotions_onehot = cat.fit_transform(formal_emotions).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eeg_s1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m23\u001b[39m):\n\u001b[1;32m      3\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (j \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m211\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(\u001b[43meeg_s1\u001b[49m[i,:,j,:])):\n\u001b[1;32m      5\u001b[0m         emotion_labels\u001b[38;5;241m.\u001b[39mappend(emotions_onehot[i])\n\u001b[1;32m      6\u001b[0m         j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eeg_s1' is not defined"
     ]
    }
   ],
   "source": [
    "emotion_labels = []\n",
    "for i in range(23):\n",
    "    j = 0\n",
    "    while (j < 211 and np.sum(eeg_s1[i,:,j,:])):\n",
    "        emotion_labels.append(emotions_onehot[i])\n",
    "        j += 1\n",
    "print(len(emotion_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = np.array(emotion_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_e = emotion_labels[train_indices]\n",
    "y_valid_e = emotion_labels[valid_indices]\n",
    "y_test_e = emotion_labels[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_e = torch.utils.data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train_e))\n",
    "val_subset_e = torch.utils.data.TensorDataset(torch.Tensor(x_valid), torch.Tensor(y_valid_e))\n",
    "test_dataset_e = torch.utils.data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test_e))\n",
    "\n",
    "train_loader_e = torch.utils.data.DataLoader(train_subset_v, shuffle=True, batch_size=bsz)\n",
    "val_loader_e = torch.utils.data.DataLoader(val_subset_v, shuffle=False, batch_size=bsz)\n",
    "test_loader_e = torch.utils.data.DataLoader(test_dataset_v, shuffle=False, batch_size=bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:01<01:33,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.521, Val acc: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:03<01:28,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.754, Val acc: 0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:05<01:22,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.878, Val acc: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:06<01:17,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.946, Val acc: 0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:08<01:15,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.984, Val acc: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:10<01:13,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.999, Val acc: 0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:11<01:10,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.999, Val acc: 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:13<01:09,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:15<01:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:16<01:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:18<01:04,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:20<01:02,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:21<01:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:24<01:06,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:26<01:05,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:27<01:03,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:29<00:59,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:31<00:56,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:32<00:53,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:34<00:50,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:35<00:47,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:37<00:45,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:39<00:44,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:40<00:41,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:42<00:39,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:43<00:38,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:45<00:37,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:47<00:35,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:48<00:34,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:50<00:33,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:53<00:38,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:56<00:40,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:57<00:35,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [00:59<00:31,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:01<00:27,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [01:02<00:25,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [01:04<00:22,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [01:05<00:20,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:07<00:18,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:09<00:16,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.991, Val acc: 0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:10<00:14,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [01:12<00:12,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.996, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [01:14<00:11,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [01:16<00:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.999, Val acc: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:17<00:08,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.996, Val acc: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:19<00:06,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.988, Val acc: 0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [01:20<00:05,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.999, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [01:22<00:03,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.000, Val acc: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [01:24<00:01,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.999, Val acc: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:26<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.997, Val acc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_net(emo_net, e_optimizer, e_criterion, train_loader_e, val_loader_e, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 1.0000000000\n"
     ]
    }
   ],
   "source": [
    "eval_net(emo_net, test_loader_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
